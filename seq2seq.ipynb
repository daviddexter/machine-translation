{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from models.utils import get_all_characters, get_vocab, get_inv_vocab, preprocess_input_data\n",
    "from models.utils import preprocess_target_data, clean_lines, get_short_sentences, decode_sequence\n",
    "from models.seq2seq import custom_model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>en</th>\n",
       "      <th>ig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>into two</td>\n",
       "      <td>yiwa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11 Like a dog that returns to its vomit, The s...</td>\n",
       "      <td>11 Dị nnọọ ka nkịta nke na-alaghachi n’agbọ ọ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rush</td>\n",
       "      <td>kpọwa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4 So his father-in-law, the young woman’s fath...</td>\n",
       "      <td>4 Ọgọ nwoke ahụ, bụ́ nna nwa agbọghọ ahụ, ekwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>trap for animals</td>\n",
       "      <td>igbụdụ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                 en  \\\n",
       "0           0                                           into two   \n",
       "1           1  11 Like a dog that returns to its vomit, The s...   \n",
       "2           2                                               rush   \n",
       "3           3  4 So his father-in-law, the young woman’s fath...   \n",
       "4           4                                   trap for animals   \n",
       "\n",
       "                                                  ig  \n",
       "0                                               yiwa  \n",
       "1  11 Dị nnọọ ka nkịta nke na-alaghachi n’agbọ ọ ...  \n",
       "2                                              kpọwa  \n",
       "3  4 Ọgọ nwoke ahụ, bụ́ nna nwa agbọghọ ahụ, ekwe...  \n",
       "4                                             igbụdụ  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of performance constraint, I will only use those sentences that are below a certain size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = 100\n",
    "Ty = 120\n",
    "english_texts, igbo_texts = get_short_sentences(dataset, Tx, Ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23399"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23399"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(igbo_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_characters = get_all_characters(english_texts)\n",
    "igbo_characters = get_all_characters(igbo_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_english_tokens = len(english_characters)\n",
    "num_igbo_tokens = len(igbo_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input 23399\n",
      "Number of unique igbo characters 119\n",
      "Number of unique english characters 94\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of input\", len(english_texts))\n",
    "print(\"Number of unique igbo characters\", num_igbo_tokens)\n",
    "print(\"Number of unique english characters\", num_english_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "igbo_vocab = get_vocab(igbo_characters)\n",
    "english_vocab = get_vocab(english_characters)\n",
    "igbo_inv_vocab = get_inv_vocab(igbo_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = preprocess_input_data(english_texts, english_vocab, Tx, num_english_tokens)\n",
    "decoder_input_data = preprocess_input_data(igbo_texts, igbo_vocab, Ty, num_igbo_tokens)\n",
    "decoder_target_data = preprocess_target_data(igbo_texts, igbo_vocab, Ty, num_igbo_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 256\n",
    "epochs = 1\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = custom_model(num_english_tokens, num_igbo_tokens, dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     (None, None, 94)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     (None, None, 119)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)             [(None, 256), (None, 359424      encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 256),  385024      decoder_inputs[0][0]             \n",
      "                                                                 encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 119)    30583       decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 775,031\n",
      "Trainable params: 775,031\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21059 samples, validate on 2340 samples\n",
      "Epoch 1/1\n",
      "21059/21059 [==============================] - 347s 16ms/step - loss: 0.8469 - val_loss: 0.7161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25fca914ac8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], \n",
    "                  decoder_target_data, \n",
    "                  batch_size=batch_size, \n",
    "                  epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = model.inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_lstm = model.get_layer(name='encoder_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = model.inputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lstm = model.get_layer(name='decoder_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dense = model.get_layer(name='decoder_dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-e18bbd3694a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mencoder_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_lstm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __call__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "encoder_model = encoder_model(encoder_inputs, encoder_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() takes 2 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-d0bf1c911b81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdecoder_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdimension\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_lstm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_dense\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __call__() takes 2 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "decoder_model = decoder_model(dimension, decoder_lstm, decoder_inputs, decoder_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:  into two\n",
      "Output:  2 na anụ anụ na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na \n",
      "Source:  11 Like a dog that returns to its vomit, The stupid one repeats his foolishness.\n",
      "Output:  we na na-enu na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na \n",
      "Source:  rush\n",
      "Output:  we na na-enu na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na \n",
      "Source:  trap for animals\n",
      "Output:  we na na-enu na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na \n",
      "Source:  cat\n",
      "Output:  2 na anụ anụ na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na \n",
      "Source:  Rhynchophorus phoenicis\n",
      "Output:  wa na na-enu na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na \n",
      "Source:  write against\n",
      "Output:  gwa anụ anụ anụ anụ na na-enu na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na n\n",
      "Source:  23 Sing to Jehovah, all the earth! Announce his salvation day after day!\n",
      "Output:  we na anụ anụ na na-enu na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na n\n",
      "Source:  5 You must love Jehovah your God with all your heart and all your soul and all your strength.\n",
      "Output:  we na na-enu na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na \n",
      "Source:  clear weeds\n",
      "Output:  2 na anụ anụ na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na na \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    input_seq = encoder_input_data[i:i+1]\n",
    "    decoded_sentence = decode_sequence(input_seq, encoder_model, num_igbo_tokens, igbo_vocab, decoder_model, igbo_inv_vocab, Ty)\n",
    "    print(\"Source: \", english_texts[i])\n",
    "    print(\"Output: \", decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
